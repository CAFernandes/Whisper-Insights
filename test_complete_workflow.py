#!/usr/bin/env python3
"""
Script de teste abrangente para o workflow completo:
1. Upload de arquivos de Ã¡udio de diferentes formatos
2. TranscriÃ§Ã£o com Whisper
3. GeraÃ§Ã£o de insights com Ollama
4. Testes de casos de erro
5. Testes de retry de insights
"""

import requests
import time
import json
import os

# ConfiguraÃ§Ãµes
FLASK_URL = "http://localhost:5001"
TEST_FILES = {
    "valid_audio": [
        ("teste_audio.m4a", "audio/m4a"),
        ("teste_audio.wav", "audio/wav"),
        ("teste_audio.ogg", "audio/ogg"),
        ("teste_audio.kwf", "audio/kwf")
    ],
    "invalid_files": [
        ("invalid_file.txt", "text/plain")
    ]
}

def test_ollama_connection():
    """Testa a conexÃ£o com o Ollama"""
    print("ğŸ” Verificando conexÃ£o com Ollama...")
    try:
        response = requests.get(f"{FLASK_URL}/check_ollama")
        data = response.json()
        if data['connected']:
            print(f"âœ… Ollama conectado com {data['count']} modelo(s): {', '.join(data['models'])}")
            return data['models']
        else:
            print("âŒ Ollama nÃ£o estÃ¡ conectado")
            return []
    except Exception as e:
        print(f"âŒ Erro ao verificar Ollama: {e}")
        return []

def test_whisper_model():
    """Testa se o modelo Whisper estÃ¡ carregado"""
    print("ğŸ” Verificando modelo Whisper...")
    try:
        response = requests.get(f"{FLASK_URL}/check_model")
        data = response.json()
        if data['success']:
            print(f"âœ… {data['message']}")
            return True
        else:
            print(f"âŒ Erro no modelo Whisper: {data['message']}")
            return False
    except Exception as e:
        print(f"âŒ Erro ao verificar modelo Whisper: {e}")
        return False

def upload_file(file_path, content_type, enable_diarization=False):
    """Faz upload de um arquivo especÃ­fico"""
    print(f"\nğŸ“¤ Fazendo upload do arquivo: {file_path}")

    if enable_diarization:
        print("ğŸ‘¥ Speaker diarization habilitado")

    if not os.path.exists(file_path):
        print(f"âŒ Arquivo {file_path} nÃ£o encontrado")
        return None, f"Arquivo {file_path} nÃ£o encontrado"

    try:
        with open(file_path, 'rb') as f:
            files = {'file': (os.path.basename(file_path), f, content_type)}

            # Adicionar parÃ¢metro de diarization se habilitado
            data_params = {}
            if enable_diarization:
                data_params['enable_diarization'] = 'true'

            response = requests.post(f"{FLASK_URL}/upload", files=files, data=data_params)

            if response.status_code == 413:
                return None, "Arquivo muito grande (413 Request Entity Too Large)"

            data = response.json()

            if data['success']:
                print(f"âœ… Upload realizado com sucesso. Task ID: {data['task_id']}")
                return data['task_id'], None
            else:
                print(f"âŒ Erro no upload: {data['message']}")
                return None, data['message']
    except Exception as e:
        print(f"âŒ Erro durante upload: {e}")
        return None, str(e)

def test_invalid_upload():
    """Testa upload de arquivo invÃ¡lido"""
    print("\nğŸš« Testando upload de arquivo invÃ¡lido...")

    for file_path, content_type in TEST_FILES["invalid_files"]:
        task_id, error = upload_file(file_path, content_type)
        if task_id is None and "nÃ£o permitido" in str(error):
            print(f"âœ… Erro esperado para {file_path}: {error}")
        else:
            print(f"âŒ Upload de arquivo invÃ¡lido nÃ£o foi rejeitado adequadamente: {file_path}")

def test_no_file_upload():
    """Testa upload sem arquivo"""
    print("\nğŸš« Testando upload sem arquivo...")
    try:
        response = requests.post(f"{FLASK_URL}/upload", files={})
        data = response.json()
        if not data['success'] and "Nenhum arquivo" in data['message']:
            print(f"âœ… Erro esperado: {data['message']}")
        else:
            print(f"âŒ Upload sem arquivo nÃ£o foi rejeitado adequadamente")
    except Exception as e:
        print(f"âŒ Erro inesperado no teste de upload sem arquivo: {e}")

def monitor_progress(task_id, wait_for_insights=False):
    """Monitora o progresso da transcriÃ§Ã£o e opcionalmente dos insights"""
    print(f"\nâ³ Monitorando progresso da task {task_id}...")

    while True:
        try:
            response = requests.get(f"{FLASK_URL}/status/{task_id}")
            data = response.json()
            status = data.get('status', 'unknown')

            if status in ['processing', 'pending_upload']:
                progress = data.get('progress', 'Processando...')
                print(f"ğŸ”„ {progress}")
                time.sleep(3)

            elif status == 'transcription_completed':
                print("âœ… TranscriÃ§Ã£o concluÃ­da com sucesso!")
                print(f"\nğŸ“ TranscriÃ§Ã£o:")
                print("-" * 50)
                text = data.get('text', '')
                print(text[:500] + "..." if len(text) > 500 else text)
                print("-" * 50)

                if not wait_for_insights:
                    return data
                else:
                    print("â³ Aguardando geraÃ§Ã£o de insights...")
                    time.sleep(2)

            elif status == 'generating_insights':
                progress = data.get('progress', 'Gerando insights...')
                print(f"ğŸ”„ {progress}")
                time.sleep(3)

            elif status in ['completed_with_insights', 'completed']:
                print("âœ… Processamento concluÃ­do com sucesso!")

                if 'text' in data:
                    print(f"\nğŸ“ TranscriÃ§Ã£o:")
                    print("-" * 50)
                    text = data.get('text', '')
                    print(text[:500] + "..." if len(text) > 500 else text)
                    print("-" * 50)

                # NOVA FUNCIONALIDADE: Exibir informaÃ§Ãµes de speaker diarization
                transcription_data = data.get('transcription_data', {})
                if transcription_data.get('speakers_text'):
                    print(f"\nğŸ‘¥ Speaker Diarization Detectado:")
                    print("-" * 50)
                    speakers_text = transcription_data['speakers_text']
                    print(speakers_text[:800] + "..." if len(speakers_text) > 800 else speakers_text)
                    print("-" * 50)

                    # Exibir resumo de speakers se disponÃ­vel
                    speakers_summary = transcription_data.get('speakers_summary', {})
                    if speakers_summary and 'speakers' in speakers_summary:
                        speakers_info = speakers_summary['speakers']
                        total_speakers = speakers_summary.get('total_speakers', 0)
                        total_duration = speakers_summary.get('total_duration', 0)

                        print(f"\nğŸ“Š Resumo de Locutores:")
                        print(f"ğŸ¤ Total de speakers identificados: {total_speakers}")
                        print(f"â±ï¸ DuraÃ§Ã£o total: {total_duration:.1f}s")

                        for speaker, info in speakers_info.items():
                            duration = info.get('total_duration', 0)
                            percentage = info.get('percentage', 0)
                            segments = info.get('segments_count', 0)
                            print(f"  â€¢ {speaker}: {duration:.1f}s ({percentage:.1f}%) - {segments} segmentos")
                        print("-" * 50)

                if 'insights' in data and data['insights']:
                    print(f"\nğŸ§  Insights gerados:")
                    print("-" * 50)
                    insights = data['insights']
                    print(insights[:1000] + "..." if len(insights) > 1000 else insights)
                    print("-" * 50)
                else:
                    print("\nâš ï¸ Nenhum insight foi gerado")

                return data

            elif status in ['error', 'error_insights']:
                print(f"âŒ Erro: {data.get('message', 'Erro desconhecido')}")
                return None

            elif status == 'not_found':
                print("âŒ Task nÃ£o encontrada")
                return None

            else:
                print(f"âš ï¸ Status desconhecido: {status}")
                time.sleep(3)

        except Exception as e:
            print(f"âŒ Erro ao verificar status: {e}")
            return None

def test_retry_insights(task_id, ollama_models):
    """Testa a funcionalidade de retry de insights"""
    print(f"\nğŸ”„ Testando retry de insights para task {task_id}...")

    if not ollama_models:
        print("âš ï¸ Nenhum modelo Ollama disponÃ­vel para teste de retry")
        return False

    custom_prompt = "ForneÃ§a um resumo executivo muito conciso em 3 pontos principais: {{text}}"

    # Priorizar modelo llama se disponÃ­vel
    selected_model = None
    for model in ollama_models:
        if "llama" in model.lower():
            selected_model = model
            break

    if not selected_model:
        selected_model = ollama_models[0]  # Fallback para o primeiro modelo disponÃ­vel

    try:
        payload = {
            "prompt": custom_prompt,
            "model_name": selected_model
        }

        response = requests.post(f"{FLASK_URL}/retry_insights/{task_id}",
                               json=payload,
                               headers={'Content-Type': 'application/json'})

        data = response.json()

        if data['success']:
            print(f"âœ… Insights gerados com sucesso usando modelo {selected_model}")
            print(f"ğŸ“ Prompt usado: {custom_prompt[:100]}...")
            if 'insights' in data:
                insights = data['insights']
                print(f"ğŸ§  Insights: {insights[:300]}...")
            return True
        else:
            print(f"âŒ Erro ao gerar insights: {data.get('message', 'Erro desconhecido')}")
            return False

    except Exception as e:
        print(f"âŒ Erro durante retry de insights: {e}")
        return False

def test_single_file_workflow(file_path, content_type, ollama_models):
    """Testa o workflow completo para um Ãºnico arquivo"""
    print(f"\n{'='*60}")
    print(f"ğŸ¯ Testando workflow para: {file_path}")
    print(f"{'='*60}")

    # Upload
    task_id, error = upload_file(file_path, content_type)
    if not task_id:
        print(f"âŒ Falha no upload: {error}")
        return False

    # Monitorar transcriÃ§Ã£o
    result = monitor_progress(task_id, wait_for_insights=False)
    if not result:
        print(f"âŒ Falha na transcriÃ§Ã£o")
        return False

    # Testar retry de insights se a transcriÃ§Ã£o foi bem-sucedida
    if result.get('status') == 'transcription_completed':
        insights_success = test_retry_insights(task_id, ollama_models)
        if insights_success:
            # Monitorar novamente para ver o resultado final
            final_result = monitor_progress(task_id, wait_for_insights=False)

    print(f"âœ… Workflow completo para {file_path}")
    return True

def test_speaker_diarization_availability():
    """Testa se a funcionalidade de speaker diarization estÃ¡ disponÃ­vel"""
    print("ğŸ” Verificando disponibilidade de Speaker Diarization...")
    try:
        response = requests.get(f"{FLASK_URL}/check_diarization_availability")
        data = response.json()
        if data['available']:
            print(f"âœ… Speaker Diarization disponÃ­vel")
            return True
        else:
            print(f"âŒ Speaker Diarization nÃ£o disponÃ­vel: {data['message']}")
            print("â„¹ï¸  Para configurar, consulte: docs/GUIA_RAPIDO_DIARIZACAO.md")
            return False
    except Exception as e:
        print(f"âŒ Erro ao verificar Speaker Diarization: {e}")
        return False

def test_speaker_diarization_workflow(file_path, content_type, ollama_models):
    """Testa o workflow especÃ­fico para speaker diarization"""
    print(f"\n{'='*60}")
    print(f"ğŸ‘¥ Testando Speaker Diarization para: {file_path}")
    print(f"{'='*60}")

    # Upload com diarization habilitado
    task_id, error = upload_file(file_path, content_type, enable_diarization=True)
    if not task_id:
        print(f"âŒ Falha no upload: {error}")
        return False

    # Monitorar transcriÃ§Ã£o
    result = monitor_progress(task_id, wait_for_insights=False)
    if not result:
        print(f"âŒ Falha na transcriÃ§Ã£o")
        return False

    # Verificar se diarization foi aplicado
    transcription_data = result.get('transcription_data', {})
    has_diarization = bool(transcription_data.get('speakers_text'))

    if has_diarization:
        print("âœ… Speaker diarization aplicado com sucesso!")

        # Testar insights com contexto de mÃºltiplos speakers
        if ollama_models:
            custom_prompt = """Analise esta transcriÃ§Ã£o que contÃ©m mÃºltiplos speakers.
            ForneÃ§a um resumo identificando os principais pontos de cada participante e a dinÃ¢mica da conversa: {{text}}"""

            insights_success = test_retry_insights_with_prompt(task_id, ollama_models, custom_prompt)
            if insights_success:
                monitor_progress(task_id, wait_for_insights=False)
    else:
        print("âš ï¸ Speaker diarization nÃ£o foi detectado (pode ser Ã¡udio com apenas um speaker ou diarizaÃ§Ã£o nÃ£o configurada)")

    return True

def test_retry_insights_with_prompt(task_id, ollama_models, custom_prompt):
    """VersÃ£o da funÃ§Ã£o de retry com prompt customizado para speakers"""
    print(f"\nğŸ”„ Testando insights com prompt customizado para speakers...")

    if not ollama_models:
        print("âš ï¸ Nenhum modelo Ollama disponÃ­vel")
        return False

    # Priorizar modelo llama se disponÃ­vel
    selected_model = None
    for model in ollama_models:
        if "llama" in model.lower():
            selected_model = model
            break

    if not selected_model:
        selected_model = ollama_models[0]

    try:
        payload = {
            "prompt": custom_prompt,
            "model_name": selected_model
        }

        response = requests.post(f"{FLASK_URL}/retry_insights/{task_id}",
                               json=payload,
                               headers={'Content-Type': 'application/json'})

        data = response.json()

        if data['success']:
            print(f"âœ… Insights com contexto de speakers gerados usando {selected_model}")
            return True
        else:
            print(f"âŒ Erro ao gerar insights: {data.get('message', 'Erro desconhecido')}")
            return False

    except Exception as e:
        print(f"âŒ Erro durante retry de insights: {e}")
        return False

def main():
    """FunÃ§Ã£o principal do teste abrangente"""
    print("ğŸš€ Iniciando suite de testes abrangente\n")

    test_results = {
        "whisper_model": False,
        "ollama_connection": False,
        "valid_files": 0,
        "invalid_files": 0,
        "no_file_upload": False,
        "insights_retry": 0,
        "speaker_diarization": False,
        "speaker_diarization_workflow": False
    }

    # 1. Verificar modelo Whisper
    print("ğŸ“‹ FASE 1: VerificaÃ§Ã£o de DependÃªncias")
    print("-" * 40)
    test_results["whisper_model"] = test_whisper_model()

    # 2. Verificar Ollama
    ollama_models = test_ollama_connection()
    test_results["ollama_connection"] = len(ollama_models) > 0

    if not test_results["whisper_model"]:
        print("\nâš ï¸ Testes abortados devido a problemas com o modelo Whisper")
        return test_results

    # 3. Testes de upload invÃ¡lido
    print(f"\nğŸ“‹ FASE 2: Testes de ValidaÃ§Ã£o de Upload")
    print("-" * 40)
    test_invalid_upload()
    test_results["invalid_files"] = len(TEST_FILES["invalid_files"])

    test_no_file_upload()
    test_results["no_file_upload"] = True

    # 4. Testes de workflow completo para arquivos vÃ¡lidos
    print(f"\nğŸ“‹ FASE 3: Testes de Workflow Completo")
    print("-" * 40)

    successful_workflows = 0
    total_valid_files = len(TEST_FILES["valid_audio"])

    for file_path, content_type in TEST_FILES["valid_audio"]:
        if os.path.exists(file_path):
            success = test_single_file_workflow(file_path, content_type, ollama_models)
            if success:
                successful_workflows += 1
                if ollama_models:  # Se tem modelos Ollama, conta como teste de insights
                    test_results["insights_retry"] += 1
        else:
            print(f"âš ï¸ Arquivo {file_path} nÃ£o encontrado, pulando teste...")

    test_results["valid_files"] = successful_workflows

    # 5. Verificar disponibilidade de Speaker Diarization
    print(f"\nğŸ“‹ FASE 4: VerificaÃ§Ã£o de Speaker Diarization")
    print("-" * 40)
    diarization_available = test_speaker_diarization_availability()
    test_results["speaker_diarization"] = diarization_available

    # Se speaker diarization estiver disponÃ­vel, testar workflow especÃ­fico
    if diarization_available:
        print(f"\nğŸ“‹ FASE 5: Testes de Workflow com Speaker Diarization")
        print("-" * 40)

        # Testar com um arquivo de Ã¡udio vÃ¡lido
        test_file = None
        for file_path, content_type in TEST_FILES["valid_audio"]:
            if os.path.exists(file_path):
                test_file = (file_path, content_type)
                break

        if test_file:
            file_path, content_type = test_file
            diarization_success = test_speaker_diarization_workflow(file_path, content_type, ollama_models)
            test_results["speaker_diarization_workflow"] = diarization_success
        else:
            print("âš ï¸ Nenhum arquivo de teste vÃ¡lido encontrado para speaker diarization")
            test_results["speaker_diarization_workflow"] = False
    else:
        test_results["speaker_diarization_workflow"] = False

    # 6. Resumo final
    print(f"\n{'='*60}")
    print("ğŸ“Š RESUMO DOS TESTES")
    print(f"{'='*60}")
    print(f"âœ… Modelo Whisper: {'OK' if test_results['whisper_model'] else 'FALHA'}")
    print(f"âœ… ConexÃ£o Ollama: {'OK' if test_results['ollama_connection'] else 'FALHA'} ({len(ollama_models)} modelos)")
    print(f"âœ… Arquivos vÃ¡lidos testados: {test_results['valid_files']}/{total_valid_files}")
    print(f"âœ… Testes de arquivo invÃ¡lido: {test_results['invalid_files']}")
    print(f"âœ… Teste upload sem arquivo: {'OK' if test_results['no_file_upload'] else 'FALHA'}")
    print(f"âœ… Testes de retry insights: {test_results['insights_retry']}")
    print(f"âœ… Disponibilidade de Speaker Diarization: {'OK' if test_results['speaker_diarization'] else 'FALHA'}")

    if test_results["speaker_diarization"]:
        print(f"âœ… Workflow com Speaker Diarization: {'OK' if test_results.get('speaker_diarization_workflow', False) else 'FALHA'}")

    # Calcular score geral
    total_tests = 8 if test_results["speaker_diarization"] else 7  # +1 se diarization workflow foi testado
    passed_tests = (
        (1 if test_results['whisper_model'] else 0) +
        (1 if test_results['ollama_connection'] else 0) +
        (1 if test_results['valid_files'] > 0 else 0) +
        (1 if test_results['invalid_files'] > 0 else 0) +
        (1 if test_results['no_file_upload'] else 0) +
        (1 if test_results['insights_retry'] > 0 else 0) +
        (1 if test_results['speaker_diarization'] else 0) +
        (1 if test_results.get('speaker_diarization_workflow', False) else 0)
    )

    success_rate = (passed_tests / total_tests) * 100
    print(f"\nğŸ¯ Taxa de Sucesso Geral: {success_rate:.1f}% ({passed_tests}/{total_tests})")

    if success_rate >= 80:
        print("ğŸ‰ Suite de testes APROVADA!")
    elif success_rate >= 60:
        print("âš ï¸ Suite de testes com AVISOS")
    else:
        print("âŒ Suite de testes REPROVADA")

    return test_results

if __name__ == "__main__":
    main()
